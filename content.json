{"meta":{"title":"lmy.blog","subtitle":null,"description":null,"author":"lmy","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"Sample DP Problems","slug":"DP-Problems","date":"2017-12-14T10:25:24.000Z","updated":"2017-12-14T10:31:51.000Z","comments":true,"path":"2017/12/14/DP-Problems/","link":"","permalink":"http://yoursite.com/2017/12/14/DP-Problems/","excerpt":"","text":"Problem1During spring break you are planning to make a road trip from Madison to Miami, and want to stop at various tourist locations along the way for sight-seeing. You have a map (in the form of a graph) of all the locations showing the time it takes to go from any one location to another. You have a limited amount of time for the trip, so you want to spend no more than x hours driving. Furthermore, you want to plan your trip in such a way that each location you visit is closer to Miami than the previous one. Design a DP-based algorithm that returns a route from Madison to Miami with total driving time at most x hours, and that visits the maximum possible number of locations enroute. Your algorithm should run in time polynomial in the size of the graph (number of vertices and edges), independent of x. SolutionSort all locations into a list by the driving time they need from their location to Miami. Suppose there are n locations in total including Madison and Miami, then Madison is the $1^{th}$ element and Miami is $n^{th}$ element. Then we can construct an array M[n, n] such that M[i, j] stores the driving time from i to j (i &lt; j). Since we want to keep the distance from our car to Miami decreasing during the trip, we cannot visit 1, …., ${i-1}^{th} $ location if we visit i. Let Opt(n, x) be the maximum number of city we can visit if our destination is the $n^{th}$ city and the duration of the trip is x. Then we can have following recurrence: $Opt(n, w) = {max(Opt(i, x - t{i,n}))}{1 &lt;= i &lt;= n-1} +1$ Then we can design our algorithm like following: 123456789Opt(n,w)&#123; C[1... n, 0....x] for i = 1 to n: for j = 0 to x: C[i,j] = max(C[k, j - M[k,i]]) + 1 // 1 ≤ k ≤ i EndFor EndFor Return C[n, w]&#125; Therefore, we can find the maximum locations that we can visit in $O(n^3)$ operations, which is polynomial time as desired. Problem2You are given an arithmetic expression containing n integers and n − 1 operators, each either +, −, or ×. Your goal is to perform the operations in an order that maximizes the value of the expression. For example: • For the expression 6 × 3 + 2 × 5, the optimal ordering is to add the middle numbers first,then perform the multiplications: ((6 × (3 + 2)) × 5) = 150. • For the expression (−3) × 3 + 3, the optimal ordering is (((−3) × 3) + 3) = −6. • For the expression (−3) × 3 − 3, the optimal ordering is ((−3) × (3 − 3)) = 0.Give a polynomial-time algorithm to find the maximum possible value of the given expression. SolutionSuppose there is an optimal solution Opt(A[n]) where A[n] is an array storing the sequnce of the numbers. Then we can observe the following recurrence $Opt(A[1: n]) = {Max(Opt(A[1:i] operation Opt(A[i: n])))}_{1&lt;=i&lt;=n} $ 123456789Opt(n)&#123; M[1...n, 1...n] for i from 1 to n: for j from j to n: M[i,j] = Max(M[i,k] operation M[k, j])))// i ≤ k ≤j EndFor EndFor Return M[1, n]&#125; Problem3Consider the setting of the weighted interval scheduling problem from class, but with two identical machines rather than a single machine. In order to execute a job, one of the machines needs to be reserved for the entire duration of the job. Develop a polynomial-time algorithm to construct an optimal schedule. solutionAssume all n tasks are distinct. That is to say, the finishing time of the last task on the first machine is different from the one on the second machine. Then we sort the n tasks in ascending order of their finishing time. Assume v(n) is the largest index of the job that compatible with $n^{th}$ task and Opt(n) is optimal solution on the set of job from 1 to n. Then, here is the reasoning: If n is not in the optimal solution: then $Opt(n) = Opt(n-1)$. We just move on to exam next task. If n is in the optimal solution: Suppose $n^{th}$ task is arranged on the first machine, then the last job on the second one would be the task which finishing time is between the $v(n)^{th}$ job and the $n^{th}$ job. ==&gt; $Opt(n) = {max(Opt(i))}_{v(n) ≤ i ≤ n -1} + 1$ Combine these two cases together we can get the following recurrence: ==&gt; $Opt(n) = max(Opt(n-1), {max(Opt(i))}_{v(n) ≤ i ≤ n -1} + 1)$ 123456789Opt(n)&#123; M[1…n, 0…w] // assume the period start from 0 for i = 1 to n: for j = 0 to w: M(i,j) = max(M(i-1, j), &#123;max(M[k,j]&#125;_&#123;v(n) ≤ k ≤ n -1&#125; + 1) EndFor EndFor Return M[n,w] &#125;","categories":[],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://yoursite.com/tags/Algorithm/"}]},{"title":"Minimum spanning tree and Proof","slug":"Minimum-spanning-tree","date":"2017-12-14T08:42:52.000Z","updated":"2017-12-14T08:45:14.000Z","comments":true,"path":"2017/12/14/Minimum-spanning-tree/","link":"","permalink":"http://yoursite.com/2017/12/14/Minimum-spanning-tree/","excerpt":"","text":"Minimum spanning treeKruskal’s Algorithm Proof. Cut Property: If edge e =(v, w) is the minimum-cost edge with one end in set S and the other in V-S, then every minimum spanning tree contains the edge e. The proof of Cut property: 构造一个比e贵的e’,找到一个treeT有e’没有e。然后证明T‘比T cheaper。 The proof of Kruskal’s Algorithm: consider any edge e = (v, w) addeed by Kruskal’s Algorithm, and let S be the set of all nodes that before e is added. so v 属于S， w属于V-S, because adding e does not create a cycle. Moreover, no edge from S to V-S has been encountered yet, since any such edge could have been added without creating a cycle. Thus e is the cheapest edge with one end in S and the other in V-S. Therefore, by cut property, it belongs to every minimum spanning tree. Complexity. O(mlogn) (use union-find) Prim’s Algorithm Proof. Complexity. O(mlogn) (use heap) Reverse-Delete Algorithm Proof. Cycle Property: ​The most expensive edge on C will not belong to any minimum spanning tree of G. The proof of cycle property: ​a path P with one end at v and the other at w, and begin in S and end up in V-S, we can find some edge e’ that crosses from S to V-S. Then consider the spanning tree with e’ and without e. ​As the proof in cut property, (first) the graph is connected and has no cycles, so the T’ is a spanning tree. (second) since e is the most expensive edge on the cycle C, and e’ belongs to C, it must be that e’ is cheaper than e, so T’ is cheaper than T as desired. ​ The proof of Reverse-Delete Algorithm ​Before e is removed, it is a part of cycle C. Since it is the first edge encountered by the algorithm in decreasing oreder of edge costs, it must be the most expensive edge on C. Then by Cycle property, e does not belong to any minimum spanning tree. ​Then prove that the output (V, T) is a spanning tree of G. (first prove it is connected) Because the algorithm never removes an edge when this will disconnect the graph, (V, T) is connected. (Then prove it is a tree, which means there is no cycle in the Graph) suppose that (V, T) contains a cycle C. Since the most expensive edge e on C will be removed by the algorithm, so there will not be cycle.","categories":[],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://yoursite.com/tags/Algorithm/"}]},{"title":"SwiftNote2","slug":"SwiftNote2","date":"2017-11-04T02:19:38.000Z","updated":"2017-11-04T02:19:58.000Z","comments":true,"path":"2017/11/03/SwiftNote2/","link":"","permalink":"http://yoursite.com/2017/11/03/SwiftNote2/","excerpt":"","text":"","categories":[],"tags":[{"name":"Swift","slug":"Swift","permalink":"http://yoursite.com/tags/Swift/"}]},{"title":"SwiftNote1","slug":"SwiftNote1","date":"2017-10-21T02:10:15.000Z","updated":"2017-10-21T04:43:53.000Z","comments":true,"path":"2017/10/20/SwiftNote1/","link":"","permalink":"http://yoursite.com/2017/10/20/SwiftNote1/","excerpt":"","text":"基本类型之常量、变量和声明 let： let maxNum = 1000 var：var index = 2 如果要同时声明多个变量，可以用语句 var x = 1, y = 2, z = 3 Swift 变量的类型是严格定义的 type inference: 初次赋值一个变量时，swift会自动判断变量类型而不需要自己标示 在Swift中，按住Option，移到变量上，可以看见变量类型 显式声明一个变量： let website: String = &quot;www.immoc.com&quot; 同时定义a b c为double类型的变量：var a , b , c : Double 基本类型之整型常用类型 int float double boolean string tuple 整型var imInt : Int = 80 整形变量的存储由计算机内存决定，可以是32bit or 16bit Int.max 可以看整形表达的最大值 同理Int.min 在编译层面上Swift就会报错，而不是运行层面 无符号整形：UInt 最小值是0 123var imUInt: UInt = 80UInt.min0 Int8 Int16 UInt16… 二进制赋值 let binaryInt: Int = 0b10001 用下划线给整形进行分割 let bignum = 1_000_000 使程序易读 基本类型之浮点数和类型转换浮点数let imFloat: Float = 3.1315926 32位的表示 let imDouble: Double = 3.1415926 64位的表示 let x = 3.1415926 会自动判断是double类型 var a = 1.25e10 科学计数法表示数 var b = 1.25e-8 也可以用下划线进行分割使程序易读 类型转换123let x: UInt16 = 100let y: UInt8 = 20let m = x + UInt16(y) 必须显式地类型转换 double 和float 也不能直接相加，需要转换 整数和小数也要转换 let w: Float = 3 是可以的，因为3可以表示为浮点数 let v: Int = 3.0 是不行的 CGFloat 1234let red: Float = 0.2let green: CGFloat = 0.5let blue: CGFloat = 0.3UIColor(red: red, green: green, blue: blue, alpha: 1.0) 基本类型之布尔类型和简单的if语句布尔类型12let imTrue: Bool = truelet imFalse = false if语句123456789if imTrue&#123; print(\"i'm True\")&#125;else if 3+4 == 7&#123; print(3+4==7)&#125;else&#123; print(\"I'm False\")&#125; 条件可以不用小括号包起来，但是大括号不能省略 不可以使用“1”“0”表示boolean值 基本类型之元组 Tuple 12var point = (5, 2)var httpResponse = (404, \"Not Found\") 可以是不同类型的变量 var point2: (Int, Int, Int) = (10, 5, 2) 显式地定义元组 var httpResponse2: (Int, String) = (200, &quot;OK&quot;) 得到元组里不同分量的值 123let (x, y) = pointpoint.0point.1 也可以获取不同分量的值，但是不直观 给元组里不同分量命名并获取 1234567let point3 = (x:3, y:2)point3.xpoint3.ylet point4:(x :Int, y: Int) = (10,5)point4.xpoint4.y 解包元组里的某一个分量 12let loginResult = (true, \"liuyubobobo\")let (isLoginSuccess, _) = loginResult 元组适合轻量级的数据 基本类型之其他：变量名、print和注释 String let website: String = &quot;www.imooc.com&quot; 变量名代码风格： 类型的名称首字母用大写 变量名不一定全部使用英文（？）可以用unicode的任意字符 可以用emoji！ 12var 名字 = \"liuyubobobo\"print (\"我的名字是\" + 名字) Print12345678print(\"Hello\")let x = 1, y = 2, z = 3, b = trueprint(x, y, z, b)//默认中间是空格print(x, y, z, separator:\",\")//会使分隔符变成逗号而不是空格print(x, y, z, separator:\"--\", terminator:\":)\")//把行尾从\\n改成:)print(y, \"*\", z, \"=\", y*z)print(\"\\(y) * \\(z) = \\(y*z)\")//字符串插值 注释多行注释之间也可以插入注释","categories":[],"tags":[{"name":"Swift","slug":"Swift","permalink":"http://yoursite.com/tags/Swift/"}]},{"title":"P/NP/NP-Complete","slug":"P-NP-NPComplete","date":"2017-07-25T23:22:03.000Z","updated":"2017-07-26T20:06:37.000Z","comments":true,"path":"2017/07/25/P-NP-NPComplete/","link":"","permalink":"http://yoursite.com/2017/07/25/P-NP-NPComplete/","excerpt":"","text":"Definitionp problem: a problem can be solved in polynomial time np problem: a candidate answer given to the problem can be tested in polynomial time np-complete: (prove) prove np every problems in NP can be reduced to an np complete (If Y is an NP-complete problem, and X is a problem in NP with theproperty that Y ≤P X, then X is NP-complete.) Which means, there is another NP-complete problem Y such that Y ≤ p X ​ ​ ​ Lemma(8.1) Suppose Y ≤P X. If X can be solved in polynomial time, then Y can besolved in polynomial time. (8.2) Suppose Y ≤P X. If Y cannot be solved in polynomial time, then Xcannot be solved in polynomial time. Classic problemVertex coverGiven a graph G = (V, E), we say that a set of nodes S ⊆ V is a vertex cover if every edge e ∈ E has at least one end in S. Reducing to Set cover Set cover: Given a set U of n elements, a collection S1, . . . , Sm of subsets of U, and a number k, does there exist a collection of at most k of these sets whose union is equal to all of U? (8.6) Vertex Cover ≤P Set Cover. Proof. Suppose we have access to a black box that can solve Set Cover, andconsider an arbitrary instance of Vertex Cover, specified by a graph G = (V , E)and a number k. How can we use the black box to help us? Our goal is to cover the edges in E, so we formulate an instance of SetCover in which the ground set U is equal to E. Each time we pick a vertex inthe Vertex Cover Problem, we cover all the edges incident to it; thus, for eachvertex i ∈ V, we add a set Si ⊆ U to our Set Cover instance, consisting of allthe edges in G incident to i. WenowclaimthatU canbecoveredwithatmostkofthesetsS1,…,Snif and only if G has a vertex cover of size at most k. This can be proved veryeasily. For if Si1,…,Sil are l≤k sets that cover U, then every edge in G isincident to one of the vertices i1,…,il, and so the set {i1,…,il} is a vertexcover in G of size l ≤ k. Conversely, if {i1, . . . , il} is a vertex cover in G of sizel≤k, then the sets Si1,…,Sil cover U. Thus, given our instance of Vertex Cover, we formulate the instance ofSet Cover described above, and pass it to our black box. We answer yes if andonly if the black box answers yes. The Satisfiability ProblemNP-Complete ProblemsArguably the most natural way to define a “hardest” problem X is via thefollowing two properties: (i) X ∈ NP; and (ii) for all Y ∈ NP, Y ≤P X. In other words, we require that every problem in NP can be reduced to X. We will callsuch an X an NP-complete problem. (8.12) Suppose X is an NP-complete problem. Then X is solvable in polyno- mial time if and only if P = NP. (8.13) Circuit Satisfiability is NP-complete. (8.14) If Y is an NP-complete problem, and X is a problem in NP with theproperty that Y ≤P X, then X is NP-complete. (8.15) 3-Satisfiability is NP-complete. (8.16) All of the following problems are NP-complete: Independent Set, SetPacking, Vertex Cover, and Set Cover. ​​​​​ References: Kleinberg, J. (2005) Algorithm Design, Pearson Education, Inc.","categories":[],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://yoursite.com/tags/Algorithm/"}]},{"title":"Dynamic programming","slug":"Dynamic-programming","date":"2017-07-11T06:37:32.000Z","updated":"2017-07-12T06:19:37.000Z","comments":true,"path":"2017/07/11/Dynamic-programming/","link":"","permalink":"http://yoursite.com/2017/07/11/Dynamic-programming/","excerpt":"","text":"Dynamic Programming 动态规划​ Unfortunally, not all problems can come to an optimal solution by greedy algorithm. Sometimes, there are no natural greedy algorithm works. Compared to divide and conquer, when facing exponential search, we can use a powerful technique, dynamic programming. ​ Dynamic programming can simply described as dividing a problem into a series of subproblems, and then building up correct solutions to larger and larger subproblems (like brute-force search). ​ 不是所有问题都能用贪心算法解决，我们可以尝试动态规划。动态规划就是把一个问题分成一系列子问题，然后把解向更高一级子问题增进。（类似穷举法） Recursive Procedure : Weighted Interval Scheduling ProblemA recursive algorithm first do recursive procedure building up solutions to larger and larger subproblems Objective: Maximize the total weight of tasks to be scheduled. $u_1, u_3,u_5$: 2 + 4 + 2 = 8 suppose that the tasks are sorted in nondecreasing finish time. we define $p(j)$ to be the largest index $i &lt; j$ that $i$ is the leftmost interval ends before $j$ begins. If no such request, $p(j) = 0$. consider an optimal solution $O$. If the last interval n is an element of $O$, then there are no interval between $p(j)$ and $j$ can belong to $O$. Also, $O$ must include an optimal solution of requests {1, …, $p(n)$}, because if didn’t, we could replace the choice of requests with a better one. If $n$ isn’t an element of $O$, then $O$ equals to the optimal solution to the problem {1, …. n-1}. Thus, for any value of $j$ between 1 and $n$, let $O_j$ denote the optimal solution to the problem {1, …, j}, and let OPT(j) denote the value of the solution. OPT(0) =0. OPT(j) = max ($v_j$ + OPT(p(j)), OPT(j-1)) —— either n belongs to $O$ or not ​ Algorithm: 123456Compute — Opt(j) if (j = 0) return 0; Else return max(U_n + Opt(P(N)), Opt(n-1))End Proof: we can proof its correction by induction. Disadvantage The algorithm written above will take exponential time to run in the worst case because the tree widens very quickly due to the recursive branching, which is like the Fibonacci numbers. Memorizing the RecursionTo reduce the running time of the algorithm we mentioned above to polynomial time, we could store the value of Compute-Opt in a globally accessible place the first time we compute it, and then use it in place of all future recursive calls. The technique is called memoization. suppose there is an array M[0,…, n], and M[j] will start with the value “empty,” but will hold the value of Compute-Opt(j) as soon as it is first determined. 123456789M-Compute-Opt(j) If j=0 then Return 0 Else if M[j] is not empty then Return M[j] Else Define M[j] = max(vj+M-Compute-Opt(p(j)), M-Compute-Opt(j − 1)) Return M[j] Endif The running time of M-Compute-Opt(n) is $O(n)$ (if the intervals are sorted by finish times) Proof At first, the number of non-empty M[j] is 0. Each time the procedure invoke the recurrence, issuing two recursicve calls to M-Compute-Opt, the number of non-empty M[j] increases by 1. Since M has only n+1 entries, it follows that there can be at most $O(n)$ calls to M-Compute-Opt, so the running time is $O(n)$ as desired. Computing a Solution in Addition to Its ValueWe know that $j$ belongs to an optimal solution for the set of intervals {1, . . . , j} if and only if vj + OPT(p(j)) ≥ OPT(j − 1). 12345678910Find-Solution(j) If j=0 then Output nothing Else If vj+M[p(j)]≥M[j−1] then Output j together with the result of Find-Solution(p(j)) Else Output the result of Find-Solution(j − 1) Endif Endif The complexity is $O(n)$. Iterative building up of subproblemsObviously, the essence of the algorithm above is the array M. We can directly compute the entries in M by an iterative algorithm instead of the memoized recursion. We start with M[0] = 0, and keep increasing $j$. 12345Iterative-Compute-Opt M[0]=0 For j=1,2,...,n M[j]= max(vj + M[p(j)], M[j − 1]) Endfor The complexity is $O(n)$. In each iteration, one entry in M will be filled. Principles: Memoization or Iteration over SubproblemsSituations that DP can be applied: The number of subproblems is polynomial. The solution of the original problem can be computed from solutions to subproblems. There is a natural ordering of problems from smallest to largest, and there is a easy-to-compute recurrence. ​ Segmented Least Squares: Multi-way ChoicesMulti-way choices: at each step, we have a polynomial number of possibilities to consider for the structure of the optimal solution, compared to only 2 in the above question. Problem 1: Linear Match of DateGiven a series of points $P_1, P_2… P_n$ with $P_i$ (i from 1 to n) = $(x_i, y_i)$ find the best match of line y = ax +b Hint: to minimize the error(L, P): Skipping the derivation and we can come to the result : the line of minimum error is y = ax + b, where If we use two lines, we could achieve quite a small error. Change DetectionGiven a sequence of data points, we want to identify a few points in the sequence at which a discrete change occurs. (In this case, a change from one linear approximation to another) References: Kleinberg, J. (2005) Algorithm Design, Pearson Education, Inc.","categories":[],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://yoursite.com/tags/Algorithm/"}]}]}